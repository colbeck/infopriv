{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_lower_bound(K, w, r): # Greedy Lower bound\n",
    "    m,n = K.shape\n",
    "    K_bar = 1-K\n",
    "    v = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        v[i] = np.ones(m) @ K_bar[:, i] * w[i]\n",
    "\n",
    "    v_srtd = np.flip(np.argsort(v))\n",
    "    v[v_srtd]\n",
    "\n",
    "    # v_srtd is the arguments of the \"most important\" features to pick\n",
    "\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        x_temp = np.copy(x)\n",
    "        x_temp[v_srtd[i]] = 1\n",
    "        if np.count_nonzero(K @ x_temp) <= m*(1-r):\n",
    "            x = x_temp\n",
    "\n",
    "    # COUNT IS LOWER BOUND\n",
    "    count = x @ w\n",
    "    return count, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_mip_upper_bound(K, w, r): # LP upper bound\n",
    "    m,n = K.shape\n",
    "    K_bar = 1 - K\n",
    "    x = cp.Variable(n, boolean = True)\n",
    "    obj = cp.Maximize(w @ x)\n",
    "    # cons = [cp.norm(K @ x, p = 0) <= m * (1-r)]\n",
    "    cons = [r * m * cp.sum(x) - np.ones(m) @ K_bar @ x <= 0]\n",
    "    # cons += [x <= 1, 0 <= x]\n",
    "\n",
    "    prob = cp.Problem(obj, cons)\n",
    "    prob.solve()\n",
    "    return prob.value, x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_mip_lower_bound(K, w, r): # LP upper bound\n",
    "    m,n = K.shape\n",
    "    x = cp.Variable(n, boolean = True)\n",
    "    obj = cp.Maximize(w @ x)\n",
    "    # cons = [cp.norm(K @ x, p = 0) <= m * (1-r)]\n",
    "    cons = [np.ones(m) @ K @ x <= m * (1-r)]\n",
    "    # cons += [x <= 1, 0 <= x]\n",
    "\n",
    "    prob = cp.Problem(obj, cons)\n",
    "    prob.solve()\n",
    "    return prob.value, x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdp_relaxation(K,w,r): # poor sdp relaxation\n",
    "    m,n = K.shape\n",
    "    K_bar = 1 - K\n",
    "    X = cp.Variable((n+m+1,n+m+1), PSD = True)\n",
    "\n",
    "    obj = cp.Maximize(w @ X[n+m,:n])\n",
    "    cons = []\n",
    "    cons += [cp.sum(X[n+m,n:n+m]) >= r*m]\n",
    "\n",
    "    for i in range(n):\n",
    "        cons += [X[i,i] == X[n+m,i]]\n",
    "    for j in range(n, n+m):\n",
    "        cons += [X[j,j] == X[n+m,j]]\n",
    "    cons += [X[m+n,m+n] == 1]\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if K[j,i] == 1:\n",
    "                cons += [X[i,n+j] == 0]\n",
    "    # cons += [X[n+m,:n] <= 1, 0 <= X[n+m,:n]]\n",
    "    cons += [X[n+m,:n+m] <= 1, 0 <= X[n+m,:n+m]]\n",
    "    cons += [r * m * cp.sum(X[n+m,:n]) - np.ones(m) @ K_bar @ X[n+m,:n] <= 0]\n",
    "\n",
    "\n",
    "    prob = cp.Problem(obj, cons)\n",
    "\n",
    "    prob.solve()\n",
    "    return prob.value, X.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_const_sat(K, r, x): # is the actual constraint satisfied\n",
    "    m,_ = K.shape\n",
    "    return np.count_nonzero(K @ x) <= m*(1-r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make random data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr.seed(5)\n",
    "\n",
    "m = 20\n",
    "n = 15\n",
    "k = 0\n",
    "\n",
    "D = npr.randint(2, size = (m,n))\n",
    "K = np.abs(D - D[k,:])\n",
    "K_bar = 1-K\n",
    "\n",
    "# information weighting vector\n",
    "w = npr.randint(0, n, size = n)\n",
    "r = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_low, x_val_low = greedy_lower_bound(K,w,r)\n",
    "p_val_mip_high, x_val_mip_high = solve_mip_upper_bound(K,w,r)\n",
    "p_val_mip_low, x_val_mip_low = solve_mip_lower_bound(K,w,r)\n",
    "\n",
    "bound_tight = true_const_sat(K, r, x_val_mip_high)\n",
    "\n",
    "p_val_high_sdp, x_val_high_sdp = sdp_relaxation(K,w,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper bound MIP =  39.0\n",
      "Lower bound MIP =  7.0\n",
      "Lower_bound =  7.0\n",
      "upper bound sdp =  19.223049401785378\n",
      "upper bound LP tight =  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Upper bound MIP = \", p_val_mip_high)\n",
    "print(\"Lower bound MIP = \", p_val_mip_low)\n",
    "print(\"Lower_bound = \", p_val_low)\n",
    "print(\"upper bound sdp = \", p_val_high_sdp)\n",
    "print(\"upper bound LP tight = \", true_const_sat(K,r, x_val_mip_high))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3ed6dde042e78d86e091991aef4e6276872e8fbcb7e1edcb6e9eacd7157f213"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
